{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b33218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.agent import Agent\n",
    "from phi.model.groq import Groq\n",
    "from phi.tools.yfinance import YFinanceTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bc060d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5381745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Agent-1\n",
    "Research_agent_1=Agent(\n",
    "    name= \"Companies research Agent\",\n",
    "    role=\"Search the web for the information\",\n",
    "    model=Groq(id = \"llama3-70b-8192\"),\n",
    "    tools=[DuckDuckGo()],\n",
    "    instructions=[\"Give in detailed information\",\"Always include sources\"],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c31a1234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running:\n",
      " - duckduckgo_search(query=Zomato)\n",
      "\n",
      "\n",
      "Running:\n",
      " - duckduckgo_news(query=Zomato news)\n",
      "\n",
      "Here is the detailed information about Zomato:\n",
      "\n",
      "**What is Zomato?**\n",
      "Zomato is an online food delivery and restaurant discovery platform that allows users to search and discover restaurants, read reviews, and order food online. The company was founded in 2008 by Deepinder Goyal and Pankaj Chaddah.\n",
      "\n",
      "**Recent News about Zomato**\n",
      "Recently, there was a viral Reddit post that claimed Zomato was losing market share and forcing employees to order exclusively on Zomato. However, Zomato CEO Deepinder Goyal has rubbished these claims, calling them \"utter nonsense\". He reaffirmed that employees have the freedom to choose which food delivery platform they want to use.\n",
      "\n",
      "**Sources:**\n",
      "* [Business Today](https://www.msn.com/en-ph/money/topstories/utter-nonsense-zomato-ceo-deepinder-goyal-rubbishes-claims-on-market-share-loss-amid-viral-reddit-post/ar-AA1DEwSw)\n",
      "* [Outlook Business](https://www.outlookbusiness.com/start-up/e-commerce/zomato-ceo-deepinder-goyal-refutes-viral-reddit-claims-on-market-share-dip-employee-ordering-rules)\n",
      "* [Times Now](https://www.msn.com/en-in/lifestyle/smart-living/is-zomato-forcing-employees-to-order-from-app-deepinder-goyal-breaks-silence-on-explosive-reddit-claims/ar-AA1DEK7r)\n",
      "* [Hindustan Times](https://www.msn.com/en-in/news/India/utter-nonsense-deepinder-goyal-hits-back-at-reddit-post-alleging-zomato-staff-banned-from-using-swiggy-zepto/ar-AA1DEvCW)\n",
      "* [The Financial Express](https://www.financialexpress.com/trending/zomatos-deepinder-goyal-tags-reddit-post-utter-nonsense-says-not-losing-market-share-or-forcing-employees/3823247/)\n"
     ]
    }
   ],
   "source": [
    "#example working of Agent-1\n",
    "company=\"Zomato\"\n",
    "response = Research_agent_1.run(company)\n",
    "\n",
    "# Only extracts the 'content'\n",
    "research_text = response.content\n",
    "\n",
    "print(research_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d79e529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#case genaration Agent\n",
    "Case_genaration_Agent_2=Agent(\n",
    "    name=\"Use case genarator Agent\",\n",
    "    role=\"Analyze the given industry/company research and generate AI/ML/GenAI based use cases to improve operations, customer experience, and efficiency.\",\n",
    "    model=Groq(id=\"llama3-70b-8192\"),\n",
    "    instructions=[\n",
    "        \"Take the input research carefully.\",\n",
    "        \"Generate at least 5 detailed use cases.\",\n",
    "        \"Ensure each use case mentions how GenAI, ML or LLMs can be applied.\",\n",
    "        \"Suggest creative as well as industry-standard ideas.\"\n",
    "    ],\n",
    "    show_tool_calls=True,\n",
    "    markdown=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "96cb75f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Zomato: AI/ML/GenAI Based Use Cases to Improve Operations, Customer Experience, and Efficiency**\n",
      "\n",
      "### Use Case 1: **Personalized Restaurant Recommendations**\n",
      "\n",
      "**Implementation:** Utilize a Generative AI model, such as a transformers-based architecture, to analyze user behavior, search history, and review patterns to provide personalized restaurant recommendations.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* Enhanced customer experience through tailored suggestions\n",
      "* Increased engagement and orders from recommended restaurants\n",
      "* Improved user retention and loyalty\n",
      "\n",
      "### Use Case 2: **Intelligent Order Routing and Fulfillment**\n",
      "\n",
      "**Implementation:** Leverage Machine Learning algorithms, such as graph-based models, to optimize order routing and fulfillment. These algorithms can analyze various factors, including:\n",
      "\n",
      "* Restaurant availability and capacity\n",
      "* Delivery personnel location and availability\n",
      "* Traffic patterns and road conditions\n",
      "* Time of day and weather\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* Reduced order fulfillment times\n",
      "* Increased delivery efficiency and reduced costs\n",
      "* Improved customer satisfaction through faster and more reliable delivery\n",
      "\n",
      "### Use Case 3: **Sentiment Analysis and Review Insights**\n",
      "\n",
      "**Implementation:** Employ Natural Language Processing (NLP) techniques and Machine Learning models to analyze user reviews and ratings. This can help identify:\n",
      "\n",
      "* Sentiment trends and patterns\n",
      "* Key drivers of positive and negative reviews\n",
      "* Restaurant-specific areas for improvement\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* Enhanced customer insights and feedback\n",
      "* Data-driven decision-making for restaurants and Zomato operations\n",
      "* Improved customer experience through targeted improvements\n",
      "\n",
      "### Use Case 4: **Predictive Demand Forecasting**\n",
      "\n",
      "**Implementation:** Utilize time-series analysis, machine learning, and GenAI models to predict demand patterns and forecast order volumes. These predictions can be based on:\n",
      "\n",
      "* Historical order data\n",
      "* Seasonal and weather patterns\n",
      "* Special events and holidays\n",
      "* Competitor activity and market trends\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* Improved planning and resource allocation for restaurants and Zomato operations\n",
      "* Reduced waste and improved inventory management\n",
      "* Enhanced customer experience through more accurate demand forecasting\n",
      "\n",
      "### Use Case 5: ** Chatbots and Conversational AI for Customer Support**\n",
      "\n",
      "**Implementation:** Develop a conversational AI-powered chatbot to handle customer inquiries, concerns, and feedback. This chatbot can be integrated with Zomato's customer support system to:\n",
      "\n",
      "* Provide instant responses to common queries\n",
      "* Route complex issues to human customer support agents\n",
      "* Offer personalized support and resolutions\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* Improved customer satisfaction and experience through timely support\n",
      "* Reduced customer support costs and increased efficiency\n",
      "* Enhanced customer insights through chatbot interactions and feedback analysis\n"
     ]
    }
   ],
   "source": [
    "#example execution of Agent-2\n",
    "use_case_response = Case_genaration_Agent_2.run(research_text)\n",
    "use_case_response_text=use_case_response.content\n",
    "print(use_case_response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "514ed5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zomato GenAI Based Use Cases Improve Operations Customer Experience\n"
     ]
    }
   ],
   "source": [
    "#Convert Agent-2's verbose output into a search query.\n",
    "\"\"\"Example Input: \n",
    "        \"**Use Case 1**: AI-powered chatbot for Workday (leveraging NLP)...\"\n",
    "    Output: \n",
    "        \"Workday chatbot NLP\"\n",
    "    \"\"\"\n",
    "import re\n",
    "\n",
    "def extract_keywords(markdown_text: str, max_keywords=5) -> str:\n",
    "    \n",
    "    # Step 1: Remove markdown formatting\n",
    "    clean_text = re.sub(r'\\*+|`+|#+', '', markdown_text)\n",
    "    \n",
    "    # Step 2: Extract capitalized/noun phrases (crude but effective)\n",
    "    keywords = re.findall(r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\b|\\b\\w{4,}\\b', clean_text)\n",
    "    \n",
    "    # Step 3: Filter and limit keywords\n",
    "    stopwords = {'for', 'and', 'the', 'with', 'using'} \n",
    "    keywords = [kw for kw in keywords if kw.lower() not in stopwords][:max_keywords]\n",
    "    \n",
    "    return \" \".join(keywords)\n",
    "\n",
    "#Example running:\n",
    "#agent2_output = \"**Use Case**: AI-powered Workday chatbot (NLP, LLMs)...\"\n",
    "print(extract_keywords(use_case_response_text))  # Output: \"Workday chatbot NLP LLMs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3e89d",
   "metadata": {},
   "source": [
    "Using kaggle, hf, and github's api for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3afc289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import json\n",
    "# Ensure the output is a string (required for tool responses).\n",
    "\n",
    "def format_output(results: Union[List[str], str]) -> str:\n",
    "    if isinstance(results, list):\n",
    "        return json.dumps(results)  # Convert list to JSON string\n",
    "    return str(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e80acf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "\n",
    "def setup_kaggle():\n",
    "    \"\"\"Ensure kaggle.json exists or use environment variables.\"\"\"\n",
    "    if not os.path.exists(os.path.expanduser(\"~/.kaggle/kaggle.json\")):\n",
    "        raise FileNotFoundError(\"Place kaggle.json in ~/.kaggle/ or set KAGGLE_USERNAME/KAGGLE_KEY env vars.\")\n",
    "\n",
    "# Kaggle\n",
    "def search_kaggle_datasets(query: str, max_results: int = 3) -> str:  # Return string!\n",
    "    try:\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        datasets = api.dataset_list(search=query)[:max_results]\n",
    "        links = [f\"https://www.kaggle.com/datasets/{d.ref}\" for d in datasets]\n",
    "        return format_output(links)  # Ensure string output\n",
    "    except Exception as e:\n",
    "        return format_output(f\"Kaggle Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b2d276c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()  # No errors = success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1458d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets\n",
    "\n",
    "def search_hf_datasets(query: str, max_results: int = 3) -> str:\n",
    "    try:\n",
    "        datasets = list(list_datasets(search=query))[:max_results]\n",
    "        links = [f\"https://huggingface.co/datasets/{d.id}\" for d in datasets]\n",
    "        return format_output(links)\n",
    "    except Exception as e:\n",
    "        return format_output(f\"HF Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "13d1ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def search_github_datasets(query: str, max_results: int = 3) -> str:\n",
    "    try:\n",
    "        # ... (your scraping code)\n",
    "        links = [...]  # List of GitHub links\n",
    "        return format_output(links)\n",
    "    except Exception as e:\n",
    "        return format_output(f\"GitHub Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "aa54880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Collector_Agent_3 = Agent(\n",
    "    name=\"Dataset Collector Agent\",\n",
    "    model=Groq(id=\"llama3-70b-8192\"),\n",
    "    tools=[search_kaggle_datasets, search_hf_datasets, search_github_datasets],\n",
    "    instructions=[\n",
    "        \"Prioritize Kaggle > HuggingFace > GitHub for datasets.\",\n",
    "        \"Format: [Platform: Title](URL)\",\n",
    "        \"Skip if no results found.\",\n",
    "        \"Never hallucinate links!\"\n",
    "    ],\n",
    "    markdown=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5a2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_use_case_titles(markdown_text: str) -> list[str]:\n",
    "    \"\"\"Extract ### headings from markdown (use case titles)\"\"\"\n",
    "    return re.findall(r'### \\d+\\. \\*\\*(.*?)\\*\\*', markdown_text)\n",
    "\n",
    "# Example:\n",
    "agent2_output = \"\"\"\n",
    "## Use Cases\n",
    "### 1. **Intelligent Inventory Management**\n",
    "### 2. **AI-Powered Chatbots**\n",
    "\"\"\"\n",
    "titles = extract_use_case_titles(use_case_response_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f9e92666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Intelligent Inventory Management dataset'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_search_query(title: str) -> str:\n",
    "    \"\"\"Convert use case title to dataset search query\"\"\"\n",
    "    # Keep only nouns/verbs (remove connectors)\n",
    "    keywords = re.sub(r'\\b(for|using|with|the)\\b', '', title)\n",
    "    return f\"{keywords} dataset\"\n",
    "\n",
    "# Example:\n",
    "create_search_query(\"Intelligent Inventory Management\") \n",
    "# -> \"Intelligent Inventory Management dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "96ac2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_datasets_for_use_cases(use_case_titles: list[str]) -> dict:\n",
    "    results = {}\n",
    "    for title in use_case_titles:\n",
    "        query = create_search_query(title)\n",
    "        response = Dataset_Collector_Agent_3.run(query)\n",
    "        results[title] = response.content\n",
    "    return results\n",
    "\n",
    "# Usage:\n",
    "datasets_by_use_case = find_datasets_for_use_cases(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "373bb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ai_use_cases_with_datasets(company: str) -> str:\n",
    "    # Step 1: Run Agent 1 â†’ Agent 2\n",
    "    research = Research_agent_1.run(f\"Find details about {company}\").content\n",
    "    use_cases_markdown = Case_genaration_Agent_2.run(research).content\n",
    "    \n",
    "    # Step 2: Process Agent 2's output\n",
    "    use_case_titles = extract_use_case_titles(use_cases_markdown)\n",
    "    datasets_by_use_case = find_datasets_for_use_cases(use_case_titles)\n",
    "    \n",
    "    # Step 3: Generate structured output\n",
    "    output = [\"## AI Use Cases with Recommended Datasets\"]\n",
    "    for title in use_case_titles:\n",
    "        output.append(f\"### {title}\")\n",
    "        output.append(datasets_by_use_case.get(title, \"No relevant datasets found\"))\n",
    "    \n",
    "    return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b54beb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## AI Use Cases with Recommended Datasets\n",
      "### Personalized Restaurant Recommendations\n",
      "[Kaggle: Restaurant Recommendations](https://www.kaggle.com/datasets/samayashar/restaurant-recommendations)\n",
      "[Kaggle: Dubai's Finest Eats - 13K Restaurant Dataset](https://www.kaggle.com/datasets/shahriarrahman009/dubais-finest-eats-13k-restaurant-dataset)\n",
      "[Kaggle: Global Zomato Dataset](https://www.kaggle.com/datasets/harishkumardatalab/global-zomato-dataset)\n",
      "### Real-time Menu Item Suggestion\n",
      "It seems like the tools didn't yield any results. I'll respond directly without using a tool. \n",
      "\n",
      "No relevant datasets were found for \"Real-time Menu Item Suggestion dataset\".\n",
      "### Predictive Food Preparation and Delivery Times\n",
      "[Kaggle: Food Delivery Order History Data](https://www.kaggle.com/datasets/sujalsuthar/food-delivery-order-history-data)\n",
      "[Kaggle: Food Delivery Time](https://www.kaggle.com/datasets/willianoliveiragibin/food-delivery-time)\n",
      "### Restaurant Performance Analytics\n",
      "[Kaggle: Zomato Delivery Operations Analytics Dataset](https://www.kaggle.com/datasets/saurabhbadole/zomato-delivery-operations-analytics-dataset)\n",
      "[Kaggle: Atlanta Restaurant Reviews](https://www.kaggle.com/datasets/grohith/atlanta-restaurant-reviews)\n",
      "[Kaggle: Food Inspection Data](https://www.kaggle.com/datasets/babatundezenith/food-inspection-data)\n",
      "[Kaggle: Italian Bistro Sales Data - A Year in Numbers](https://www.kaggle.com/datasets/divyanshisen/italian-bistro-sales-data-a-year-in-numbers)\n",
      "[Kaggle: Submission JSON](https://www.kaggle.com/datasets/sharmilaghosh/submission-json)\n",
      "[Kaggle: Zomato Project](https://www.kaggle.com/datasets/umairhayat/zomato-project)\n",
      "[Kaggle: Restaurant Performance Analysis](https://www.kaggle.com/datasets/parthaade/restaurant-performance-analysis)\n",
      "[Kaggle: Swiggy Data Set for Visulization](https://www.kaggle.com/datasets/renu2407/swiggydata-set-for-visulization)\n",
      "### Virtual Restaurant Concierge\n",
      "No relevant datasets were found.\n"
     ]
    }
   ],
   "source": [
    "# Test with Walmart\n",
    "result = generate_ai_use_cases_with_datasets(company)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
